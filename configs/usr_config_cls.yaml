wandb:
  enable: true
  api_key: ???  # your wandb api key
  entity: ???  # the place to save your runs. can be your wandb username or team name
  project: ???  # the name of your project
  name: ???
train:
  epochs: 200
  dataloader:
    selected_points: 2048  # points to be selected from every point cloud
    fps: false  #  whether to use fps to select points. if false, use random downsample to select points
    combine_trainval: true  # combine train and validation set as train set
    batch_size_per_gpu: 2
    num_workers: 2  # the number of subprocess to load data
    prefetch: ${train.dataloader.batch_size_per_gpu}  # samples to be prefetched. e.g. 64 means 64*num_workers samples to be prefetched
    pin_memory: true  # pin memory in RAM
  lr: 1e-4
  lr_scheduler:
    which: cos_warmupLR
    stepLR:
      gamma: 0.2
      decay_step: 60
    cosLR:
      T_max: ${train.epochs}
      eta_min: 1e-8
    cos_warmupLR:
      warmup_epochs: 10  # number of epochs the warmup process takes
      warmup_init_lr: ${train.lr_scheduler.cos_warmupLR.eta_min}  # initial warmup lr
      T_max: 190  # number of epochs the cosine annealing process takes. should be epochs - warmup_epochs
      eta_min: 1e-8  # minimum lr of cosine annealing process
  optimizer:
    which: adamw  # adamw or sgd
    weight_decay: 1
  consistency_loss_factor: 1
  validation_freq: 1
  label_smoothing: false
  amp: false  # whether to use automatic mixed precision
  ddp:
    which_gpu: [0]
    syn_bn: false  # synchronize batch normalization among gpus
    master_addr: localhost  # don't change this if you use only one PC
    master_port: 12345  # please choose an available port
    nnodes: 1  # how many PCs you want to use
    nproc_this_node: 1  # how many gpu you want to use in current PC, should match 'which_gpu'
    rank_starts_from: 0  # don't change this if you use only one PC
    world_size: 1 # this is equal to 'nproc_this_node' if you only use one PC

test:  # only valid when running the test script
  label_smoothing: false
  epsilon: 0.2  # epsilon for label smoothing
  dataloader:
    batch_size_per_gpu: 2
    num_workers: 2  # ${test.ddp.nproc_this_node}  # the number of subprocess to load data
    prefetch: ${test.dataloader.batch_size_per_gpu}  # samples to be prefetched. e.g. 64 means 64*num_workers samples to be prefetched
    pin_memory: true  # pin memory in RAM
  ddp:
    which_gpu: [0]
    master_addr: localhost  # don't change this if you use only one PC
    master_port: 12345  # please choose an available port
    nnodes: 1  # how many PCs you want to use
    nproc_this_node: 1  # how many gpu you want to use in current PC, should match 'which_gpu'
    rank_starts_from: 0  # don't change this if you use only one PC
    world_size: 1  # this is equal to 'nproc_this_node' if you only use one PC
  visualize_preds:
    enable: false
    format: png  # png or ply
    vis_which: [0, 4]  # which category to be visualized
    num_vis: 5  # how many point clouds to visualize for one category
  visualize_downsampled_points:
    enable: false
    format: png  # png or ply
    vis_which: [0, 4, 7, 8, 15, 17, 19, 26]  # which category to be visualized
    num_vis: 1  # how many point clouds to visualize for one category
  visualize_attention_heatmap:
    enable: false
    format: png  # png or ply
    vis_which: [0, 4]  # which category to be visualized
    num_vis: 5  # how many point clouds to visualize for one category

# the layer order inside the block is:
# embedding -> neighbor2point -> downsample -> neighbor2point -> downsample -> neighbor2point
#                             -> upsample -> neighbor2point -> upsample.-> neighbor2point
neighbor2point_block:
  enable: true
  edgeconv_embedding:
    K: [32, 32]
    group_type: [center_diff, center_diff, center_diff]  # neighbor, diff, center_neighbor or center_diff
    conv1_in: [6, 128]
    conv1_out: [64, 64]
    conv2_in: [64, 64]
    conv2_out: [64, 64]
  downsample:
    which_ds: global   # local or global
    K: [1024, 512]
    q_in: [128, 128]
    q_out: [128, 128]
    k_in: [128, 128]
    k_out: [128, 128]
    v_in: [128, 128]
    v_out: [128, 128]
    num_heads: [1, 1]
  neighbor2point:
    K: [32, 32, 32]  # 3 values in the list means neighbor2point_block includes 3 neighbor2point layers. The 'K' for each layer is 40, 40 and 40 respectively
    group_type: [diff, diff, diff]  # diff, neighbor, center_neighbor or center_diff
    q_in: [128, 128, 128]
    q_out: [128, 128, 128]
    k_in: [128, 128, 128]
    k_out: [128, 128, 128]
    v_in: [128, 128, 128]
    v_out: [128, 128, 128]
    num_heads: [4, 4, 4]
    ff_conv1_channels_in: [128, 128, 128]
    ff_conv1_channels_out: [512, 512, 512]
    ff_conv2_channels_in: [512, 512, 512]
    ff_conv2_channels_out: [128, 128, 128]

# the layer order inside the block is:
# embedding -> edgeconv -> downsample -> edgeconv -> downsample -> edgeconv
#                       -> upsample -> edgeconv -> upsample -> edgeconv
edgeconv_block:
  enable: false
  edgeconv_embedding:
    K: [32, 32]
    group_type: [center_diff, center_diff]  # neighbor, diff, center_neighbor or center_diff
    conv1_in: [6, 128]
    conv1_out: [64, 64]
    conv2_in: [64, 64]
    conv2_out: [64, 64]
  downsample:
    which_ds: p2p   # p2p or n2p
    K: [1024, 512]
    q_in: [128, 128]
    q_out: [128, 128]
    k_in: [128, 128]
    k_out: [128, 128]
    v_in: [128, 128]
    v_out: [128, 128]
    num_heads: [1, 1]
  edgeconv:
    K: [32, 32, 32]
    group_type: [center_diff, center_diff, center_diff]  # neighbor, diff, center_neighbor or center_diff
    conv1_in: [256, 256, 256]
    conv1_out: [128, 128, 128]
    conv2_in: [128, 128, 128]
    conv2_out: [128, 128, 128]

# the layer order inside the block is:
# embedding -> point2point -> downsample -> point2point -> downsample -> point2point
#                          -> upsample -> point2point -> upsample -> point2point
point2point_block:
  enable: false
  edgeconv_embedding:
    K: [32, 32]
    group_type: [center_diff, center_diff]  # neighbor, diff, center_neighbor or center_diff
    conv1_in: [6, 128]
    conv1_out: [64, 64]
    conv2_in: [64, 64]
    conv2_out: [64, 64]
  downsample:
    which_ds: p2p   # p2p or n2p
    K: [1024, 512]
    q_in: [128, 128]
    q_out: [128, 128]
    k_in: [128, 128]
    k_out: [128, 128]
    v_in: [128, 128]
    v_out: [128, 128]
    num_heads: [1, 1]
  upsample:
    q_in: [64, 64]
    q_out: [64, 64]
    k_in: [64, 64]
    k_out: [64, 64]
    v_in: [64, 64]
    v_out: [64, 64]
    num_heads: [4, 4]
  point2point:
    q_in: [128, 128, 128]
    q_out: [128, 128, 128]
    k_in: [128, 128, 128]
    k_out: [128, 128, 128]
    v_in: [128, 128, 128]
    v_out: [128, 128, 128]
    num_heads: [4, 4, 4]
    ff_conv1_channels_in: [128, 128, 128]
    ff_conv1_channels_out: [512, 512, 512]
    ff_conv2_channels_in: [512, 512, 512]
    ff_conv2_channels_out: [128, 128, 128]
